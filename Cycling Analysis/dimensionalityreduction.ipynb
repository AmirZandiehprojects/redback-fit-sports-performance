{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stat import FILE_ATTRIBUTE_SPARSE_FILE\n",
    "\n",
    "\n",
    "#pip install FILE_ATTRIBUTE_SPARSE_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Activity Type\n",
       "Run                1553\n",
       "Ride                487\n",
       "Swim                223\n",
       "Virtual Ride         46\n",
       "Weight Training      31\n",
       "Workout               8\n",
       "Walk                  3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "activities_df = pd.read_csv('data/strava_activities.csv')\n",
    "\n",
    "# Count the number of activities for each Activity Type\n",
    "activity_counts = activities_df['Activity Type'].value_counts()\n",
    "activity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Activity ID          Activity Date Activity Name Activity Type  \\\n",
      "0    477882782   1 Jan 2016, 21:21:39   Morning Run           Run   \n",
      "1    477882787  17 Jan 2016, 22:05:40   Morning Run           Run   \n",
      "2    477882788  18 Jan 2016, 22:18:36   Morning Run           Run   \n",
      "3    477882789  16 Jan 2016, 21:10:39   Morning Run           Run   \n",
      "4    477882792  19 Jan 2016, 23:02:41   Morning Run           Run   \n",
      "\n",
      "  Activity Description  Elapsed Time Distance  Max Heart Rate  \\\n",
      "0                  NaN          6948    21.15             NaN   \n",
      "1                  NaN          2680     8.09             NaN   \n",
      "2                  NaN          2657     8.17             NaN   \n",
      "3                  NaN          5401    16.43             NaN   \n",
      "4                  NaN          2587     8.11             NaN   \n",
      "\n",
      "   Relative Effort  Commute  ... Total Grit Average Flow Flagged  \\\n",
      "0              NaN    False  ...        NaN          NaN     NaN   \n",
      "1              NaN    False  ...        NaN          NaN     NaN   \n",
      "2              NaN    False  ...        NaN          NaN     NaN   \n",
      "3              NaN    False  ...        NaN          NaN     NaN   \n",
      "4              NaN    False  ...        NaN          NaN     NaN   \n",
      "\n",
      "   Average Elapsed Speed  Dirt Distance  Newly Explored Distance  \\\n",
      "0                    NaN            NaN                      NaN   \n",
      "1                    NaN            NaN                      NaN   \n",
      "2                    NaN            NaN                      NaN   \n",
      "3                    NaN            NaN                      NaN   \n",
      "4                    NaN            NaN                      NaN   \n",
      "\n",
      "   Newly Explored Dirt Distance  Activity Count  Total Steps  Media  \n",
      "0                           NaN             NaN          NaN    NaN  \n",
      "1                           NaN             NaN          NaN    NaN  \n",
      "2                           NaN             NaN          NaN    NaN  \n",
      "3                           NaN             NaN          NaN    NaN  \n",
      "4                           NaN             NaN          NaN    NaN  \n",
      "\n",
      "[5 rows x 87 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter activities for the 'Run' activity type\n",
    "run_activities_df = activities_df[activities_df['Activity Type'] == 'Run']\n",
    "\n",
    "# Display the first few rows of the run activities DataFrame\n",
    "print(run_activities_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of running data before removing null values: (1553, 87)\n"
     ]
    }
   ],
   "source": [
    "# Filter activities for the 'Run' activity type\n",
    "run_activities_df = activities_df[activities_df['Activity Type'] == 'Run']\n",
    "\n",
    "# Print dimensions of running data before removing null values\n",
    "print(\"Dimensions of running data before removing null values:\", run_activities_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity ID                        0\n",
      "Activity Date                      0\n",
      "Activity Name                      0\n",
      "Activity Type                      0\n",
      "Activity Description            1544\n",
      "                                ... \n",
      "Newly Explored Distance         1553\n",
      "Newly Explored Dirt Distance    1553\n",
      "Activity Count                  1553\n",
      "Total Steps                     1544\n",
      "Media                           1553\n",
      "Length: 87, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in each column\n",
    "null_counts = run_activities_df.isnull().sum()\n",
    "\n",
    "# Display the count of null values in each column\n",
    "print(null_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Activity ID          Activity Date  \\\n",
      "0       477882782   1 Jan 2016, 21:21:39   \n",
      "1       477882787  17 Jan 2016, 22:05:40   \n",
      "2       477882788  18 Jan 2016, 22:18:36   \n",
      "3       477882789  16 Jan 2016, 21:10:39   \n",
      "4       477882792  19 Jan 2016, 23:02:41   \n",
      "...           ...                    ...   \n",
      "2341  10123458734  25 Jun 2023, 01:02:41   \n",
      "2344  10123465749  27 Jun 2023, 04:34:42   \n",
      "2347  10123472446  29 Jun 2023, 05:05:11   \n",
      "2348  10123474604  30 Jun 2023, 06:04:06   \n",
      "2350  10271579059  19 Nov 2023, 00:21:15   \n",
      "\n",
      "                                          Activity Name Activity Type  \\\n",
      "0                                           Morning Run           Run   \n",
      "1                                           Morning Run           Run   \n",
      "2                                           Morning Run           Run   \n",
      "3                                           Morning Run           Run   \n",
      "4                                           Morning Run           Run   \n",
      "...                                                 ...           ...   \n",
      "2341                               Southbank / Brighton           Run   \n",
      "2344  Southbank / Melbourne, Royal Botanic Gardens V...           Run   \n",
      "2347                               Southbank / Richmond           Run   \n",
      "2348                              Southbank / Melbourne           Run   \n",
      "2350                               Southbank / Brighton           Run   \n",
      "\n",
      "      Elapsed Time Distance  Max Heart Rate  Relative Effort  Commute  \\\n",
      "0             6948    21.15             NaN              NaN    False   \n",
      "1             2680     8.09             NaN              NaN    False   \n",
      "2             2657     8.17             NaN              NaN    False   \n",
      "3             5401    16.43             NaN              NaN    False   \n",
      "4             2587     8.11             NaN              NaN    False   \n",
      "...            ...      ...             ...              ...      ...   \n",
      "2341          7632    21.13           185.0            366.0    False   \n",
      "2344          4615    13.26           173.0            219.0    False   \n",
      "2347          3384    10.14           174.0            130.0    False   \n",
      "2348          3433     9.10           175.0             44.0    False   \n",
      "2350          9053    23.97           151.0            104.0    False   \n",
      "\n",
      "                           Filename  ...  Elevation Low  Elevation High  \\\n",
      "0       activities/529262621.tcx.gz  ...           41.5       56.799999   \n",
      "1       activities/529262641.tcx.gz  ...            NaN             NaN   \n",
      "2       activities/529262642.tcx.gz  ...            NaN             NaN   \n",
      "3       activities/529262639.tcx.gz  ...            NaN             NaN   \n",
      "4       activities/529262645.tcx.gz  ...            NaN             NaN   \n",
      "...                             ...  ...            ...             ...   \n",
      "2341  activities/10843966339.fit.gz  ...            6.1       12.600000   \n",
      "2344  activities/10843973828.fit.gz  ...            8.9       43.500000   \n",
      "2347  activities/10843980813.fit.gz  ...            8.2       16.400000   \n",
      "2348  activities/10843983156.fit.gz  ...            9.2       43.500000   \n",
      "2350  activities/10998332486.fit.gz  ...            5.6       12.700000   \n",
      "\n",
      "      Max Grade  Average Grade  Max Cadence  Average Cadence  \\\n",
      "0      0.400000      -0.072336          NaN              NaN   \n",
      "1      0.000000       0.000000          NaN              NaN   \n",
      "2      0.000000       0.000000          NaN              NaN   \n",
      "3      0.000000       0.000000          NaN              NaN   \n",
      "4      0.000000       0.000000          NaN              NaN   \n",
      "...         ...            ...          ...              ...   \n",
      "2341   7.826087      -0.001893         97.0        81.720116   \n",
      "2344  36.729153      -0.000754         86.0        80.785339   \n",
      "2347   6.954666      -0.000985         86.0        75.150879   \n",
      "2348  14.920899       0.000000         86.0        73.345657   \n",
      "2350   7.992195       0.000000         89.0        81.441574   \n",
      "\n",
      "      Average Heart Rate     Calories  Relative Effort.1  Commute.1  \n",
      "0                    NaN  2177.970459                NaN        0.0  \n",
      "1                    NaN          NaN                NaN        0.0  \n",
      "2                    NaN   843.259766                NaN        0.0  \n",
      "3                    NaN          NaN                NaN        0.0  \n",
      "4                    NaN   837.025940                NaN        0.0  \n",
      "...                  ...          ...                ...        ...  \n",
      "2341          170.416290  1437.000000              366.0        0.0  \n",
      "2344          169.754639   943.000000              219.0        0.0  \n",
      "2347          164.251862   693.000000              130.0        0.0  \n",
      "2348          141.533081   645.000000               44.0        0.0  \n",
      "2350          140.624573  1691.000000              104.0        0.0  \n",
      "\n",
      "[1553 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove columns with more than 1500 null values\n",
    "activities_df_filtered = run_activities_df.dropna(thresh=len(activities_df) - 1500, axis=1)\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(activities_df_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity ID             0\n",
      "Activity Date           0\n",
      "Activity Name           0\n",
      "Activity Type           0\n",
      "Elapsed Time            0\n",
      "Distance                0\n",
      "Max Heart Rate        508\n",
      "Relative Effort       508\n",
      "Commute                 0\n",
      "Filename                3\n",
      "Athlete Weight        525\n",
      "Elapsed Time.1         17\n",
      "Moving Time             0\n",
      "Distance.1              0\n",
      "Max Speed               3\n",
      "Elevation Gain          9\n",
      "Elevation Low         295\n",
      "Elevation High        295\n",
      "Max Grade               3\n",
      "Average Grade           0\n",
      "Max Cadence           364\n",
      "Average Cadence       359\n",
      "Average Heart Rate    508\n",
      "Calories              260\n",
      "Relative Effort.1     508\n",
      "Commute.1              22\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the filtered DataFrame\n",
    "null_counts_filtered = activities_df_filtered.isnull().sum()\n",
    "\n",
    "# Display the count of null values in each column\n",
    "print(null_counts_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cleaned DataFrame: (475, 26)\n"
     ]
    }
   ],
   "source": [
    "# Remove null values from the filtered DataFrame\n",
    "cleaned_running_data = activities_df_filtered.dropna()\n",
    "\n",
    "# Display the shape of the cleaned DataFrame\n",
    "print(\"Shape of cleaned DataFrame:\", cleaned_running_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '23 Feb 2019, 17:57:21'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Now implementing PCA on the dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m Himani_pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m Himani_df \u001b[38;5;241m=\u001b[39m Himani_pca\u001b[38;5;241m.\u001b[39mfit_transform(cleaned_running_data)\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;124;03mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 462\u001b[0m U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[0;32m    463\u001b[0m U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:485\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA does not support sparse input. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTruncatedSVD for a possible alternative.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[1;32m--> 485\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    486\u001b[0m     X, dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32], ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    487\u001b[0m )\n\u001b[0;32m    489\u001b[0m \u001b[38;5;66;03m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:810\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    809\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[1;32m--> 810\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(new_dtype)\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    812\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\himan\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '23 Feb 2019, 17:57:21'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as pt\n",
    "import numpy as np\n",
    "# Now implementing PCA on the dataset\n",
    "Himani_pca = PCA(n_components=10)\n",
    "Himani_df = Himani_pca.fit_transform(cleaned_running_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
